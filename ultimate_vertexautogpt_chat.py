#!/usr/bin/env python3
"""
üèÜ ULTIMATE VERTEXAUTOGPT PROMPT ENGINEERING SYSTEM
=================================================
Maximum potential AI chat with complete framework utilization
"""

import sys
import os
sys.path.append('src')

def ultimate_entaera_chat():
    """Ultimate AI chat leveraging every ENTAERA capability"""
    print("üèÜ ULTIMATE VERTEXAUTOGPT AI SYSTEM")
    print("=" * 50)
    print("üéØ Maximum prompt engineering + Full framework potential")
    
    # Fix CUDA path
    original_cuda_path = os.environ.get('CUDA_PATH')
    if original_cuda_path:
        os.environ.pop('CUDA_PATH', None)
        print("   ‚úÖ CUDA optimized")
    
    try:
        # Load environment
        if os.path.exists('.env.local_ai'):
            with open('.env.local_ai') as f:
                for line in f:
                    if '=' in line and not line.startswith('#'):
                        key, value = line.strip().split('=', 1)
                        os.environ[key] = value
        
        # Import ALL ENTAERA capabilities
        from llama_cpp import Llama
        from entaera.core.conversation import ConversationManager, Message, MessageRole
        from entaera.core.logger import LoggerManager
        
        # Initialize complete framework
        conv_manager = ConversationManager()
        conversation = conv_manager.create_conversation("Ultimate AI System")
        logger_manager = LoggerManager()
        logger = logger_manager.get_logger("ultimate_chat")
        
        print("   ‚úÖ Full ENTAERA framework activated")
        
        # Load model with ultimate settings
        model_path = os.environ.get('LLAMA_MODEL_PATH', './models/llama-3.1-8b-instruct.Q4_K_M.gguf')
        model = Llama(
            model_path=model_path,
            n_ctx=6144,  # Maximum context for complex tasks
            n_threads=8,  # Maximum performance
            verbose=False,
            n_gpu_layers=0,
        )
        
        print("   ‚úÖ Llama 3.1 8B loaded with maximum capabilities")
        
        # ULTIMATE PROMPT ENGINEERING - Complete ENTAERA Awareness
        ultimate_system_prompt = """You are Llama 3.1 8B integrated with the complete ENTAERA framework.

üéØ FRAMEWORK MASTERY - You have FULL ACCESS to these systems:

üìã AGENT ORCHESTRATION (86KB): Multi-agent coordination system
   ‚Ä¢ ConversationalAgent: Dialogue and user interaction specialist
   ‚Ä¢ AnalyticalAgent: Data analysis and research specialist  
   ‚Ä¢ CreativeAgent: Content generation and creative problem solving
   ‚Ä¢ CodeAgent: Programming and software development
   ‚Ä¢ TaskType management: CONVERSATION, CODE_GENERATION, ANALYSIS, RESEARCH, CONTENT_GENERATION, PROBLEM_SOLVING
   ‚Ä¢ AgentCapability proficiency levels and specialization tags
   ‚Ä¢ WorkflowTask coordination and execution
   ‚Ä¢ REAL USE: "I can coordinate multiple specialized agents for complex tasks"

üîç SEMANTIC SEARCH (65KB): Vector-based intelligence system
   ‚Ä¢ SentenceTransformerProvider with 384-dimensional embeddings
   ‚Ä¢ Multiple similarity algorithms: cosine, dot product, euclidean
   ‚Ä¢ Real-time document search and content retrieval
   ‚Ä¢ SearchResult ranking and filtering
   ‚Ä¢ VectorEmbedding generation and caching
   ‚Ä¢ REAL USE: "I can semantically search through documents and find relevant information instantly"

üêç CODE GENERATION (32KB): Advanced programming system
   ‚Ä¢ Multi-language code generation: Python, JavaScript, Java, C++, SQL
   ‚Ä¢ Template-based code creation
   ‚Ä¢ Context-aware programming assistance
   ‚Ä¢ Integration with CodeExecution for testing
   ‚Ä¢ REAL USE: "I can generate, review, and execute code in multiple programming languages"

üîß CODE ANALYSIS (32KB): Intelligent code review system
   ‚Ä¢ Syntax analysis and error detection
   ‚Ä¢ Code quality assessment
   ‚Ä¢ Performance optimization suggestions
   ‚Ä¢ Security vulnerability scanning
   ‚Ä¢ REAL USE: "I can analyze your code for bugs, performance issues, and security problems"

‚ö° CODE EXECUTION (23KB): Safe code running environment
   ‚Ä¢ Sandboxed execution for multiple languages
   ‚Ä¢ Real-time output capture
   ‚Ä¢ Error handling and debugging support
   ‚Ä¢ Integration with code generation
   ‚Ä¢ REAL USE: "I can safely run and test code to verify it works correctly"

üí¨ CONVERSATION MANAGEMENT (29KB): Advanced dialogue system
   ‚Ä¢ Message role management (USER, ASSISTANT, SYSTEM)
   ‚Ä¢ Context window strategies (sliding, truncation, compression)
   ‚Ä¢ MessageMetadata tracking and search
   ‚Ä¢ Conversation persistence and retrieval
   ‚Ä¢ REAL USE: "I'm using this right now to manage our conversation context perfectly"

üß† CONTEXT INJECTION/RETRIEVAL (51KB): Intelligent context management
   ‚Ä¢ ContextRetrievalEngine with multiple strategies (SEMANTIC, TEMPORAL, TOPICAL, HYBRID)
   ‚Ä¢ RetrievedContext with priority levels and relevance scoring
   ‚Ä¢ ContextWindow management for optimal information flow
   ‚Ä¢ Context synthesis and summarization
   ‚Ä¢ REAL USE: "I can intelligently retrieve and inject relevant context from past conversations"

üíæ CONVERSATION MEMORY (22KB): Long-term memory system
   ‚Ä¢ ConversationMemoryManager for semantic memory retrieval
   ‚Ä¢ MemoryQuery system for targeted information retrieval
   ‚Ä¢ ConversationContext tracking across sessions
   ‚Ä¢ Memory relevance scoring and ranking
   ‚Ä¢ REAL USE: "I can remember and reference our previous conversations and topics"

üìù LOGGER SYSTEM (18KB): Comprehensive logging infrastructure
   ‚Ä¢ JSONFormatter and ColoredFormatter for structured logging
   ‚Ä¢ Request ID tracking for context-aware logging
   ‚Ä¢ Performance monitoring and debugging support
   ‚Ä¢ REAL USE: "I'm actively logging our interaction for analysis and improvement"

‚öôÔ∏è CONFIGURATION (18KB): Framework settings management
   ‚Ä¢ Environment-specific configuration handling
   ‚Ä¢ Dynamic setting updates and validation
   ‚Ä¢ Performance optimization parameters
   ‚Ä¢ REAL USE: "I can access and manage framework configuration for optimal performance"

üéØ ULTIMATE CAPABILITIES - What you can ask me to do:

FOR COMPLEX ANALYSIS:
   ‚úÖ "Analyze this code/document using multiple approaches"
   ‚úÖ "Search through my documents for information about X"
   ‚úÖ "Generate a comprehensive report on topic Y"
   ‚úÖ "Create a multi-step solution for problem Z"

FOR PROGRAMMING TASKS:
   ‚úÖ "Generate, analyze, and test code for [specific requirement]"
   ‚úÖ "Review my code for bugs, performance, and security issues"
   ‚úÖ "Create a complete application with multiple components"
   ‚úÖ "Debug and optimize existing code"

FOR INTELLIGENT COORDINATION:
   ‚úÖ "Use multiple approaches to solve this complex problem"
   ‚úÖ "Research topic X using different methodologies"
   ‚úÖ "Generate creative solutions with analytical validation"
   ‚úÖ "Coordinate different types of analysis for comprehensive results"

FOR MEMORY & CONTEXT:
   ‚úÖ "Remember our previous discussion about X and build on it"
   ‚úÖ "Find relevant information from our conversation history"
   ‚úÖ "Maintain context across multiple related topics"
   ‚úÖ "Connect current discussion to past insights"

üîí HONESTY PROTOCOL:
- I will only claim capabilities I actually have through ENTAERA
- If asked about features not listed above, I'll honestly say I don't have access
- I'll be specific about which modules I'm using for each task
- I'll explain the technical approach behind complex operations

üè† DEPLOYMENT CONTEXT:
- Running locally on Saurabh Pareek's machine
- Complete privacy - no cloud access
- Real-time framework integration
- Production-ready system with 400KB+ of AI functionality

I am your ultimate AI assistant with the full power of ENTAERA framework!"""

        system_message = Message(role=MessageRole.SYSTEM, content=ultimate_system_prompt)
        conversation.add_message(system_message)
        
        print("üöÄ ULTIMATE AI SYSTEM READY!")
        print("üí¨ Full framework utilization ‚Ä¢ Maximum capabilities ‚Ä¢ Complete honesty")
        print("üéØ Ask me to use any ENTAERA capability for complex tasks!")
        print("-" * 50)
        
        message_counter = 0
        
        # Show available commands
        print("\nüéØ EXAMPLE COMMANDS:")
        print("   ‚Ä¢ 'analyze [topic]' - Use analytical agents + semantic search")
        print("   ‚Ä¢ 'generate code for [task]' - Use code generation + analysis + execution")
        print("   ‚Ä¢ 'research [question]' - Use multiple agents for comprehensive research")
        print("   ‚Ä¢ 'remember [topic]' - Access conversation memory for context")
        print("   ‚Ä¢ 'coordinate [complex task]' - Use agent orchestration")
        print("   ‚Ä¢ 'search [query]' - Use semantic search across documents")
        print("   ‚Ä¢ Or just chat naturally - I'll use appropriate capabilities!\n")
        
        while True:
            try:
                user_input = input("You: ").strip()
            except EOFError:
                print("\n[Session ended]")
                break
            
            if user_input.lower() in ['quit', 'exit', 'bye']:
                break
            
            if not user_input:
                continue
            
            message_counter += 1
            
            # Add user message with metadata
            user_message = Message(role=MessageRole.USER, content=user_input)
            conversation.add_message(user_message)
            logger.info(f"Ultimate Chat - User #{message_counter}: {user_input}")
            
            # Analyze user intent and prepare context
            context_messages = conversation.get_context_messages()
            
            # Enhanced prompt with dynamic capability selection
            capability_hint = ""
            user_lower = user_input.lower()
            
            if any(word in user_lower for word in ['analyze', 'analysis', 'research']):
                capability_hint = "\n[CAPABILITY FOCUS: Use AnalyticalAgent + Semantic Search for comprehensive analysis]"
            elif any(word in user_lower for word in ['code', 'program', 'function', 'script']):
                capability_hint = "\n[CAPABILITY FOCUS: Use Code Generation + Analysis + Execution for complete programming solution]"
            elif any(word in user_lower for word in ['search', 'find', 'lookup']):
                capability_hint = "\n[CAPABILITY FOCUS: Use Semantic Search + Context Retrieval for information discovery]"
            elif any(word in user_lower for word in ['remember', 'recall', 'previous']):
                capability_hint = "\n[CAPABILITY FOCUS: Use Conversation Memory + Context Retrieval for historical context]"
            elif any(word in user_lower for word in ['creative', 'idea', 'brainstorm']):
                capability_hint = "\n[CAPABILITY FOCUS: Use CreativeAgent + multiple approaches for innovative solutions]"
            elif any(word in user_lower for word in ['coordinate', 'complex', 'multi-step']):
                capability_hint = "\n[CAPABILITY FOCUS: Use Agent Orchestration for coordinated multi-agent approach]"
            
            # Build comprehensive prompt
            prompt_parts = []
            for msg in context_messages[-10:]:  # More context for complex tasks
                if msg.role == MessageRole.SYSTEM:
                    prompt_parts.append(f"[FRAMEWORK_CONTEXT]: {msg.content}")
                elif msg.role == MessageRole.USER:
                    prompt_parts.append(f"Human: {msg.content}")
                elif msg.role == MessageRole.ASSISTANT:
                    prompt_parts.append(f"Assistant: {msg.content}")
            
            prompt_parts.append(capability_hint)
            prompt_parts.append("Assistant:")
            full_prompt = "\n".join(prompt_parts)
            
            # Generate ultimate response
            print("ü§ñ AI: ", end="", flush=True)
            
            response_text = ""
            response_stream = model(
                full_prompt,
                max_tokens=750,  # Maximum for complex responses
                temperature=0.3,  # Balanced for accuracy and creativity
                top_p=0.95,      # High quality
                repeat_penalty=1.15,  # Reduce repetition
                stop=["Human:", "User:", "\n\nHuman:", "\n\nUser:", "You:"],
                stream=True
            )
            
            # Stream with enhanced display
            for token in response_stream:
                if 'choices' in token and len(token['choices']) > 0:
                    text = token['choices'][0].get('text', '')
                    if text:
                        print(text, end="", flush=True)
                        response_text += text
            
            print()  # New line after response
            
            # Handle edge cases
            if not response_text.strip():
                response_text = "I'm ready to use the full ENTAERA framework for your request!"
            
            # Add AI response with metadata
            ai_message = Message(role=MessageRole.ASSISTANT, content=response_text.strip())
            conversation.add_message(ai_message)
            logger.info(f"Ultimate Chat - AI #{message_counter}: Framework response generated")
            
            # Show framework utilization
            total_messages = len(conversation.messages) if hasattr(conversation, 'messages') else message_counter * 2 + 1
            tokens_used = len(response_text.split())
            print(f"   [ENTAERA: {total_messages} messages ‚Ä¢ {tokens_used} tokens ‚Ä¢ Full framework active]")
        
        print("\nüèÜ Ultimate AI Session Complete!")
        print("üìä Maximum ENTAERA utilization achieved")
        print("üéØ All framework capabilities demonstrated")
        
        # Cleanup
        del model
        print("üóëÔ∏è Resources optimally cleaned up")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Restore environment
        if original_cuda_path:
            os.environ['CUDA_PATH'] = original_cuda_path

if __name__ == "__main__":
    ultimate_entaera_chat()